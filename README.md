# workshop2 - films classifing 

Был исследован массив фильмов, размеченных по уровням сложности. Перед исследованием субтитры фильмов осчищались, проводилась их лемматизация и стемизация, проводилась работа по исправлению дисбаланса классов, после чего формировались данные по технологиям Bowl of Words и TF-IDF. Данные исследования проводились на разных N-gamm-ах (N=1/2/3).
Точности получившихся моделей крайне низки (лучший результат получился для модели Logistic Regression, стеммизованных данных сформированных по технологии BoW **Test Accuracy: 0.547945205479452 F1: 0.49617003367003365**).

Также был произведен подсчет слов, входящих в разные уровни сложности, в соответствии с рекомендациями The Oxford CEFR level. На этих данных была построена модель **Случайный лес** точность которой также очень не высока.

Дальнейшие направления исследования.
1. Попоробовать разные лемматизаторы. Или использовать разные параметры лемматизатора из библиотеки NLTK. На необходимость оптимизации этого процесса указывает анализ слов, которые не попали ни в один из уровней сложности (А1, А2 и т.д.)
1. Исследовать поведение моделей в зависимости от разных гиперпараметров.
1. Попоробовать другие подходы по исправлению дисбалланса классов (сейчас использован самый наивный алгоритм - умножение членов наименьших классов). Возможный подход - генерация синтетических текстов на основнии имеющихся предложений существующих фильмов.
1. Использование дополнительных внешних списков с перечнем фильмов с указанием их сложности (возникает проблема субъективности таких градаций). 
